<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <title>Transformer Attention Mechanism</title>
  <link rel="icon" href="../assets/blueside_logo.png" type="image/png">
  <script src="https://cdn.tailwindcss.com"></script>
</head>
<body class="bg-gray-50 text-gray-800 font-sans leading-relaxed">
  <main class="max-w-3xl mx-auto px-4 py-10">
    
    <a href="../index.html" class="text-blue-600 underline text-sm mb-6 inline-block hover:text-blue-800 transition">&larr; Back</a>
    
    <header class="mb-6">
      <div class="flex items-center space-x-3">
        <img src="../assets/blueside_logo.png" alt="Logo" class="w-10 h-10 rounded" />
        <h1 class="text-3xl font-bold text-gray-900">Transformer Attention Mechanism</h1>
      </div>
      <div class="mt-2 text-xs text-gray-500 space-y-1">
        <p>2025-08-02</p>
        <p>#self-attention #multi-head-attention</p>
        <div class="flex items-center space-x-1">
          <span>View on GitHub:</span>
          <a href="https://github.com/jdspell/blueside-code/tree/main/attention" class="text-blue-600 hover:underline">attention code</a>
        </div>
      </div>
    </header>

    <article class="space-y-8 text-sm text-gray-800">

      <section>
        <details open class="border-b border-gray-300 pb-4">
          <summary class="text-lg font-semibold cursor-pointer select-none mb-2 text-gray-900">
            Resources
          </summary>
          <p class="mb-4">
            The content presented in this blog is based on my notes from the following resources.
            I highly recommend exploring these articles and papers directly for a deeper understanding,
            especially if you're diving into self-attention and transformer-based architectures.
          </p>
          <div class="space-y-3">
            <a href="https://magazine.sebastianraschka.com/p/understanding-and-coding-self-attention"
              class="block p-3 border border-gray-200 rounded-md hover:bg-gray-50 transition text-sm bg-white">
              <div class="font-medium text-gray-900">Understanding and Coding Self-Attention</div>
              <div class="text-xs text-gray-600">Sebastian Raschka</div>
            </a>
            <a href="https://theaisummer.com/attention/"
              class="block p-3 border border-gray-200 rounded-md hover:bg-gray-50 transition text-sm bg-white">
              <div class="font-medium text-gray-900">Illustrated Guide to Attention Mechanism</div>
              <div class="text-xs text-gray-600">AI Summer</div>
            </a>
            <a href="https://arxiv.org/abs/1706.03762"
              class="block p-3 border border-gray-200 rounded-md hover:bg-gray-50 transition text-sm bg-white">
              <div class="font-medium text-gray-900">Attention Is All You Need</div>
              <div class="text-xs text-gray-600">Vaswani et al., 2017 (arXiv)</div>
            </a>
            <a href="https://arxiv.org/abs/1409.0473"
              class="block p-3 border border-gray-200 rounded-md hover:bg-gray-50 transition text-sm bg-white">
              <div class="font-medium text-gray-900">Neural Machine Translation by Aligning and Translating</div>
              <div class="text-xs text-gray-600">Bahdanau et al., 2014 (arXiv)</div>
            </a>
            <a href="https://lilianweng.github.io/posts/2018-06-24-attention/"
              class="block p-3 border border-gray-200 rounded-md hover:bg-gray-50 transition text-sm bg-white">
              <div class="font-medium text-gray-900">The Illustrated Transformer</div>
              <div class="text-xs text-gray-600">Lilian Weng, 2018</div>
            </a>
          </div>
        </details>
      </section>
      
      <section>
        <h2 class="text-lg font-semibold text-gray-900 mb-2">Overview</h2>
        <p>
          Starting with self-attention, we learn how an input is transformed to query, key, and value components using the respective weight matrices. The following procedure multiplies queries by keys to obtain attention scores, which are then normalized with the softmax function to get attention weights.
        </p>
        <p>
          These weights are multiplied against the values matrix computed from the input, and the result is a context vector for the input. The computation of a single context vector is done with a single head, and this can be extended to multiple heads. The process of multi-head attention is simply computing context vectors independently for each head. The result is then concatenated and returned.
        </p>
        <p>
          Finally, to ensure that the context vector does not contain predictions for future words within the input (i.e., each word only depends on preceding words), we can apply a mask. This is equivalent to zeroing out the upper-right triangle of the context matrix, with normalization occurring before or after to ensure each row sums to 1. Masking is particularly useful when generating output sequences to prevent future token leakage.
        </p>
      </section>

      <section>
        <h2 class="text-lg font-semibold text-gray-900 mb-2">History</h2>
        <p>
          Sequence-to-sequence learning was originally dominated by encoder-decoder architectures linked by a single context vector. The encoder/decoder models were typically RNNs or LSTMs. These models struggled with long sequences due to issues like vanishing gradients and forgotten inputs.
        </p>
        <p>
          A key limitation was the fixed-length context vector, which could fail to capture all relevant input information. Attention was introduced to directly connect each output to the entire input sequence, enabling the model to weight different parts of the input as needed.
        </p>
      </section>

      <section>
        <h2 class="text-lg font-semibold text-gray-900 mb-2">Intuition</h2>
        <ul class="list-disc list-inside space-y-2">
          <li>Attention is about finding alignment between pieces of an input. Attention scores reflect how "aligned" two tokens are.</li>
          <li>A single token can align with multiple other tokens â€” attention allows for one-to-many relationships.</li>
          <li>As sequence length increases, attention's computational cost grows quadratically.</li>
          <li>Connecting the context vector to the full input sequence is critical to ensure no information is lost in long sequences.</li>
        </ul>
      </section>

    </article>
  </main>
</body>
</html>
